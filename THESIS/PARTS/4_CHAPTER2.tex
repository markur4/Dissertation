

% ======================================================================
% == Chapter 2 ========================================================
% ======================================================================
% Das schrieb die GSLS an mich
% Zusätzliche Einleitung und Diskussion: Herr Kuric soll bitte eine ergänzende
% Einleitung und Diskussion in dem Kapitel zu seiner JOSS-Publikation
% hinzufügen, die folgende Informationen enthalten:

% Darstellung von Umfeld, Aufgabenstellung und Signifikanz für die
% biomedizinische Anwendung
% (warum braucht es die Biomedizin?)

% Darstellung der Anforderungen an die Programmierung: Integration von
% Informationen, die die spezifischen Anforderungen verdeutlichen,
% welche die Programmierung der Software erforderlich gemacht haben.
% (warum habe ich es gebraucht?) 

% Darstellung der Nutzbarkeit für Naturwissenschaftler: Klare und auch
% für Nicht-Informatiker verständliche Darstellung, welche konkreten
% Anwendungsmöglichkeiten die Software für Naturwissenschaftler bietet.
% (warum ist es nützlich?)

% Mit einer angemessenen Einleitung und Diskussion würde zum einen den
% Guidelines der GSLS entsprochen, die für alle zugrunde gelegt werden.
% Zum anderen würde es auch dem großen Anteil von Nicht-Informatikern in
% der GSLS erlauben, den Hintergrund und die Signifikanz und
% Verwendungsmöglichkeiten des entwickelten Codes besser zu verstehen.
% Die GSLS hat sich mit der Aufnahme von informatischen Projekten
% interdisziplinär geöffnet. Gleichzeitig erwarten wir damit aber auch
% von den Doktorierenden den Willen, die Arbeit in einer
% interdisziplinären Form in der Thesis zu präsentieren.

\unnsection{Chapter 2: Semi-Automating Data Analysis with \texttt{plotastic}}
\label{sec:C2}
%%%%%%%%%%
\vspace{-\baselineskip} % > Remove space made by empty lines

% ## Reset reference counters of figs, tabs, so each chapter starts at 1
\setcounter{figure}{0}
\setcounter{table}{0}


% ======================================================================
% == Abstract
% ======================================================================

\customabstract{sec:C2_abstract}{Abstract}{
      \texttt{plotastic} addresses the challenges of transitioning from
      exploratory data analysis to hypothesis testing in Python's data science
      ecosystem. Bridging the gap between \texttt{seaborn} and
      \texttt{pingouin}, this library offers a unified environment for plotting
      and statistical analysis. It simplifies the workflow with user-friendly
      syntax and seamless integration with familiar \texttt{seaborn} parameters
      (y, x, hue, row, col). Inspired by \texttt{seaborn}'s consistency,
      \texttt{plotastic} utilizes a \texttt{DataAnalysis} object to
      intelligently pass parameters to \texttt{pingouin} statistical functions.
      Hence, statistics and plotting are performed on the same set of
      parameters, so that the strength of \texttt{seaborn} in visualizing
      multidimensional data is extended onto statistical analysis. In essence,
      \texttt{plotastic} translates \texttt{seaborn} parameters into statistical
      terms, configures statistical protocols based on intuitive plotting syntax
      and returns a \texttt{matplotlib} figure with known customization options
      and more. This approach streamlines data analysis, allowing researchers to
      focus on correct statistical testing and less about specific syntax and
      implementations.
}

\newpage



% ======================================================================
% == Introduction
% ======================================================================
\unnsubsection{Introduction}%
\label{sec:C2_introduction}%
%%%
The reproducibility crisis in research highlights a significant challenge in
contemporary biosciences, where a substantial portion of studies faces
reproducibility issues~\cite{baker500ScientistsLift2016,
      begleyReproducibilityScienceImproving2015,
      gosselinInsufficientTransparencyStatistical2021}. One critical yet often
overlooked aspect contributing to this crisis is data management. The literature
most often refers to \textit{big data} as the main
challenge~\cite{gomez-cabreroDataIntegrationEra2014}. However, these challenges
are also present in smaller datasets, which the author refers to as
\textit{semi-big data}. This term describes datasets that -- while not extensive
enough to necessitate advanced computational tools typically reserved for
\textit{big data} -- are sufficiently large to render manual analysis very
time-intensive.~Semi-big data is often generated by methods like automated
microscopy or multiplex qPCR, which produce volumes of data that are manageable
on a surface level, but pose substantial barriers for in-depth, manual
reproducibility~\cite{bustinReproducibilityBiomedicalResearch2014,
      incertiYouStillUsing2019a}. This is further complicated by the complexity
inherent in multidimensional datasets \cite{krzywinskiMultidimensionalData2013}:
Modern biosciences describe processes (e.g. cell-adhesion) that are highly
dependent on multiple experimental parameters (factors), like \textit{`time'} or \textit{`kinds
of treatments'} \cite{reblTimedependentMetabolicActivity2010,
      mckayCellcellAdhesionMolecules1997}. Manually grouping the data by multiple
factors (facetting) is challenging and error-prone, especially when the data is
not structured in a way that is immediately compatible with statistical tests.
Without a clearly documented data analysis protocol and standardized data
formats, analysis of multidimensional data becomes nontransparent and too
overwhelming for reproduction
\cite{bustinReproducibilityBiomedicalResearch2014}.



The evolving standards in data analysis advocate for the standardization of
analytical pipelines, rationalization of sample sizes, and enhanced
infrastructure for data storage, addressing some of these challenges
\cite{goodmanWhatDoesResearch2016, wilkinsonFAIRGuidingPrinciples2016}. However,
these advancements can place undue pressure on researchers, particularly those
with limited training in statistics, underscoring the need for intuitive,
user-friendly analytical tools \cite{federerDataLiteracyTraining2016,
      lakhlifiIllusionKnowledgeStatistics2023, armstrongWhenUseBonferroni2014,
      gomez-lopezPrecisionMedicineNeeds2019, leekStatisticsValuesAre2015}.

In this context, \texttt{plotastic} emerges as a tool designed to democratize
access to sophisticated statistical analysis, offering a user-centric interface
that caters to researchers across varying levels of statistical proficiency.
\texttt{plotastic} simplifies inferential statistics based on the idea that
statistical analyses are often performed based on how the data is visualized.
This principle is not only intuitive but also statistically sound,
because the parameters that structure the figure (e.g. facetting) are often
times re-used for statistical testing (e.g. independent variables or factors).
By integrating robust statistical methodologies within an accessible framework,
\texttt{plotastic} could to contribute to enhancing the reproducibility of
research in the biosciences \cite{gomez-cabreroDataIntegrationEra2014}.

\texttt{plotastic} key design feature is centralizing the facetting
parameters utilized by \texttt{seaborn} into a \texttt{DataAnalysis} object.
\texttt{seaborn} uses the parameters \facetparams as arguments for many plotting functions. These
parameters lay out the structure of the plot, such as which data points are
shown on the x-axis, what categories are highlighted by color (hue), and how
data is grouped into separate plots (by columns and/or rows). By centralizing
these parameters, \texttt{plotastic} ensures that all subsequent analysis steps
do not require the user to re-specify these parameters, automating not only
statistical analysis, but also all edits applied to the plot, such as
$p$-value annotations. 

% \pagebreak

The user-centric approach of \texttt{plotastic} distinguishes itself from the
fully automated pipelines used for big data, which are designed to handle
extensive computational tasks. Instead, \texttt{plotastic} focuses on
ease-of-use and structures its commands to enable an interactive review of
intermediate outputs, a concept the author refers to as \textit{semi-automation}
(\autoref{tab:semi-auto-principles}).

\begin{table}[h]
      \caption{Key Principles of Semi-Automation and their Implementation in Plotastic}
      \footnotesize
      \centering
      \label{tab:semi-auto-principles}
      \begin{tabular}{|c|p{0.50\textwidth}|p{0.35\textwidth}|}
            \hline
            \textbf{No.}
             & \textbf{Principle}
             & \textbf{Implementation in \texttt{plotastic}}
            \\
            \hline
            1
             & \textbf{Standardized input:} The data to-be-analyzed follows a
            strict standardized format. The user should be able to convert their
            data into that format.
             & Long-format \texttt{pandas} \texttt{DataFrames} are used as input
            \\
            \hline
            2
             & \textbf{Automation over flexibility:} If there is an obvious way
            to do things, automate it and minimize user input. User options
            should be added with good reason. Avoid situations where the user is
            asked to pass the same parameter twice. This reduces the risk of
            human error, confusion and time spent on configuration.
             & E.g.
            passing the parameter ``subject'' once makes the rest of the
            pipeline switch automatically to the paired versions of statistical
            tests.
            \\
            \hline
            3%
             & \textbf{\emph{Out of the box} functionality:} The software's
            default configuration should provide acceptable (but potentially
            sub-optimal) results. Beginners should be invited to experiment
            without the need to learn custom configurations. Options are still
            available to allow feature-rich adaptions according to the needs of
            both data and user.%
             & Default tests are standard unpaired t-tests and ANOVA             %
            \\%
            \hline
            4
             & \textbf{Focus on intermediate outputs:} The user composes the
            analysis pipeline using smaller commands that are each designed to
            provide human-readable output of an intermediate result. Each step
            is a stage to control quality, allowing quick error detection and
            troubleshooting.
             & Processing steps are separated into main steps:
            assumption tests, factor analysis, post-hoc analysis and plotting
            \\
            \hline
            5
             & \textbf{Highly useful error messages:} Never leave the user
            hanging. Tell him what went wrong \emph{and} what the software was
            expecting.
             & E.g.: \texttt{ValueError: User passed 'subect' as
            subject, please choose one of ['subject', 'event', 'region']}        \\
            \hline
      \end{tabular}
\end{table}



The need for \texttt{plotastic} in this specific project arose from two main
challenges (for further details, see summarizing discussion). The first is the
author's need for a tool that could handle the complex, multidimensional data
generated by e.g. qPCR experiments. These experiments involved the analysis of
multiple outcomes across multiple genes, timepoints, method variations,
cell-types, biological replicates, technical replicates etc., resulting in
datasets that are challenging to analyse manually. Such complexity was
necessary, since establishing new methods required extensive controls and
creative variation of the experimental setup. Data analysis had to be automated
somehow, since the lab-work itself was already time-intensive. The second
challenge was to accept the potential of plot-configured statistical analyses.
The author believes that the way data is visualized is often the way it should
be analyzed. This vision is not limited to biomedical application, but a general
principle that could benefit the scientific community overall. Making
\texttt{plotastic} a generalized tool was a conscious decision to maximize its
adoption rate and ensure its long-term relevance and quality, of which biomedical
research will also benefit.


% author's vision to make statistical analysis easier by

% frustration about current practices of statistical
% analyses in biomedicine. Something had to be done, especially with the
% reproducibility crisis (see Introduction for details).






% == Paper as pdf ======================================================
% > You could import .pdf here, but chapter based theses should apply the 
% > manuscripts into the formatting of the thesis
% \addpdf[.93]
% {Software Article: Journal of Open Source Software}
% {PUBLICATIONS/§-kuricPlotasticBridgingPlotting2024.pdf}




% ======================================================================
% == Statement of Need
% ======================================================================
\unnsubsection{Statement of Need}%
\label{sec:C2_need}%
Python's data science ecosystem provides powerful tools for both visualization
and statistical testing. However, the transition from exploratory data analysis
to hypothesis testing can be cumbersome, requiring users to switch between
libraries and adapt to different syntaxes.~\texttt{seaborn} has become a popular
choice for plotting in Python, offering an intuitive interface. Its statistical
functionality focuses on descriptive plots and bootstrapped confidence
intervals~\cite{waskomSeabornStatisticalData2021}. The library \texttt{pingouin}
offers an extensive set of statistical tests, but it lacks integration with
common plotting capabilities~\cite{vallatPingouinStatisticsPython2018}.
\texttt{statannotations} integrates statistical testing with plot annotations,
but uses a complex interface and is limited to pairwise
comparisons~\cite{charlierTrevismdStatannotationsV02022}.

\texttt{plotastic} addresses this gap by offering a unified environment for
plotting and statistical analysis. With an emphasis on user-friendly
syntax and integration of familiar \texttt{seaborn} parameters, it simplifies
the process for users already comfortable with \texttt{seaborn}. The library
ensures a smooth workflow, from data import to hypothesis testing and
visualization.



\newpage



% ======================================================================
% == Example
% ======================================================================
\unnsubsection{Example}%
\label{sec:C2_example}%
%%%%%%%%%%%%%%%%%%%%%%%%%
The following code demonstrates how \texttt{plotastic} analyzes the
example dataset ``fmri'', similar to \citet{waskomSeabornStatisticalData2021}
(\autoref{fig:examplefmri}).

\begin{lstlisting}[
    language=Python, 
    style=pythonstyle,
    xrightmargin=0.03\textwidth,
    ]
### IMPORT PLOTASTIC
import plotastic as plst

# IMPORT EXAMPLE DATA
DF, _dims = plst.load_dataset("fmri", verbose = False)

# EXPLICITLY DEFINE DIMENSIONS TO FACET BY
dims = dict(
      y = "signal",    # y-axis, dependent variable
      x = "timepoint", # x-axis, independent variable (within-subject factor)
      hue = "event",   # color,  independent variable (within-subject factor)
      col = "region"   # axes,   grouping variable
)
# INITIALIZE DATAANALYSIS OBJECT
DA = plst.DataAnalysis(
      data=DF,           # Dataframe, long format
      dims=dims,         # Dictionary with y, x, hue, col, row 
      subject="subject", # Datapoints are paired by subject (optional)
      verbose=False,     # Print out info about the Data (optional)
)
# STATISTICAL TESTS
DA.check_normality()   # Check Normality
DA.check_sphericity()  # Check Sphericity
DA.omnibus_rm_anova()  # Perform RM-ANOVA
DA.test_pairwise()     # Perform Posthoc Analysis

# PLOTTING
(DA
.plot_box_strip()     # Pre-built plotting function initializes plot
.annotate_pairwise(   # Annotate results from DA.test_pairwise()
      include="__HUE" # Use only significant pairs across each hue
      ) 
)
\end{lstlisting}



\includeimage[0.9]{
      FIGS/C2_fmri2.png
}\figcaption[fig:examplefmri]{
      Example figure of \texttt{plotastic} (version 0.1). Image style was set
      by \texttt{plt.style.use(`ggplot')}
}



\begin{table}[H]
      \small
      \centering
      \caption{Results from \texttt{DA.check\_sphericity()}. \texttt{plotastic}
            assesses sphericity after grouping the data by all grouping dimensions
            (hue, row, col). For example, \texttt{DA.check\_sphericity()} grouped the
            `fmri' dataset by ``region'' (col) and ``event'' (hue), performing four
            subsequent sphericity tests for four datasets.}
      \begin{tabular}{llcccccc}
            \hline
            `region', `event'  & spher & W        & chi2   & dof & pval & group count & n per group \\
            \hline
            `frontal', `cue'   & True  & 3.26e+20 & -462.7 & 44  & 1    & 10          & [14]        \\
            `frontal', `stim'  & True  & 2.45e+17 & -392.2 & 44  & 1    & 10          & [14]        \\
            `parietal', `cue'  & True  & 1.20e+20 & -452.9 & 44  & 1    & 10          & [14]        \\
            `parietal', `stim' & True  & 2.44e+13 & -301.9 & 44  & 1    & 10          & [14]        \\
            \hline
      \end{tabular}
      \label{tab:sphericity}
\end{table}



\begin{table}[H]
      \small
      \centering
      \caption{Results of \texttt{DA.omnibus\_rm\_anova()}. \texttt{plotastic}
            performs one two-factor RM-ANOVA per axis (grouping the data by row and
            col dimensions) using x and hue as the within-factors. For this example,
            \texttt{DA.omnibus\_rm\_anova()} grouped the `fmri' dataset by ``region''
            (col), performing two subsequent two-factor RM-ANOVAs. Within-factors are
            ``timepoint'' (x) and ``event'' (hue). For conciseness, GG-Correction and
            effect sizes are not shown.}
      \begin{tabular}{llccccccc}
            \hline
            `region'   & Source            & SS    & ddof1 & ddof2 & MS    & F      & p-unc    & stars \\
            \hline
            `parietal' & timepoint         & 1.583 & 9     & 117   & 0.175 & 26.20  & 3.40e-24 & ****  \\
            `parietal' & event             & 0.770 & 1     & 13    & 0.770 & 85.31  & 4.48e-07 & ****  \\
            `parietal' & timepoint * event & 0.623 & 9     & 117   & 0.069 & 29.54  & 3.26e-26 & ****  \\
            `frontal'  & timepoint         & 0.686 & 9     & 117   & 0.076 & 15.98  & 8.28e-17 & ****  \\
            `frontal'  & event             & 0.240 & 1     & 13    & 0.240 & 23.44  & 3.21e-4  & ***   \\
            `frontal'  & timepoint * event & 0.242 & 9     & 117   & 0.026 & 13.031 & 3.23e-14 & ****  \\
            \hline
      \end{tabular}
      \label{tab:RMANOVA}
      \vspace{\vfull} % > Add vertical space since a caption is next
\end{table}


% ======================================================================
% == Overview
% ======================================================================
\unnsubsection{Overview}%
\label{sec:C2_overview}%
%%%%%%%%%%%%%%%%%%%%%%%%%
The functionality of \texttt{plotastic} revolves around a seamless integration
of statistical analysis and plotting, leveraging the capabilities of
\texttt{pingouin}, \texttt{seaborn}, \texttt{matplotlib} and
\texttt{statannotations} \cite{vallatPingouinStatisticsPython2018,
      waskomSeabornStatisticalData2021, hunterMatplotlib2DGraphics2007,
      charlierTrevismdStatannotationsV02022}. It utilizes long-format \texttt{pandas}
\texttt{DataFrames} as its primary input, aligning with the conventions of
\texttt{seaborn} and ensuring compatibility with existing data
structures~\cite{wickhamTidyData2014a, reback2020pandas,
      mckinneyDataStructuresStatistical2010}.

\texttt{plotastic} was inspired by \texttt{seaborn} using the same set of intuitive
and consistent parameters (y, x, hue, row, col) found in each of its
plotting functions \cite{waskomSeabornStatisticalData2021}. These parameters
intuitively delineate the data dimensions plotted, yielding `facetted'
subplots, each presenting y against x. This allows for rapid and
insightful exploration of multidimensional relationships.~\texttt{plotastic}
extends this principle to statistical analysis by storing these
\texttt{seaborn} parameters (referred to as dimensions) in a \texttt{DataAnalysis}
object and intelligently passing them to statistical functions of the
\texttt{pingouin} library. This approach is based on the impression that most
decisions during statistical analysis can be derived from how the user
decides to arrange the data in a plot. This approach also prevents code
repetition and streamlines statistical analysis. For example, the
subject keyword is specified only once during \texttt{DataAnalysis}
initialisation, and \texttt{plotastic} selects the appropriate paired or
unpaired version of the test. Using \texttt{pingouin} alone requires the user
to manually pick the correct test and to repeatedly specify the subject
keyword in each testing function.

In essence, \texttt{plotastic} translates plotting parameters into their
statistical counterparts. This translation minimizes user input and also
ensures a coherent and logical connection between plotting and
statistical analysis. The goal is to allow the user to focus on choosing
the correct statistical test (e.g. parametric vs. non-parametric) and
worry less about specific implementations.

At its core, \texttt{plotastic} employs iterators to systematically group data
based on various dimensions, aligning the analysis with the distinct
requirements of tests and plots. Normality testing is performed on each
individual sample, which is achieved by splitting the data by all
grouping dimensions and also the x-axis (hue, row, col, x). Sphericity
and homoscedasticity testing is performed on a complete sampleset listed
on the x-axis, which is achieved by splitting the data by all grouping
dimensions (hue, row, col)  (\autoref{tab:sphericity}). For omnibus and
posthoc analyses, data is grouped by the row and col dimensions in
parallel to the \texttt{matplotlib} axes, before performing one two-factor
analysis per axis using x and hue as the within/between-factors.
(\autoref{tab:RMANOVA}).

\texttt{DataAnalysis} visualizes data through predefined plotting functions
designed for drawing multi-layered plots. A notable emphasis within
\texttt{plotastic} is placed on showcasing individual datapoints alongside
aggregated means or medians. In detail, each plotting function
initializes a \texttt{matplotlib} figure and axes using \texttt{plt.subplots()} while
returning a \texttt{DataAnalysis} object for method chaining. Axes are
populated by \texttt{seaborn} plotting functions (e.g., \texttt{sns.boxplot()}),
leveraging automated aggregation and error bar displays. Keyword
arguments are passed to these \texttt{seaborn} functions, ensuring the same
degree of customization. Users can further customize plots
by chaining \texttt{DataAnalysis} methods or by applying common \texttt{matplotlib} code
to override \texttt{plotastic} settings. Figures are exported using
\texttt{plt.savefig()}.

\texttt{plotastic} also focuses on annotating statistical information within
plots, seamlessly incorporating p-values from pairwise comparisons using
\texttt{statannotations} \cite{charlierTrevismdStatannotationsV02022}. This
integration simplifies the interface and enables options for pair
selection in multidimensional plots, enhancing both user experience and
interpretability.

For statistics, \texttt{plotastic} integrates with the \texttt{pingouin} library
to support classical assumption and hypothesis testing, covering
parametric/non-parametric and paired/non-paired variants. Assumptions such as
normality, homoscedasticity, and sphericity are tested. Omnibus tests include
two-factor RM-ANOVA, ANOVA, Friedman, and Kruskal-Wallis. Posthoc tests are
implemented through \texttt{pingouin.pairwise\_tests()}, offering (paired)
t-tests, Wilcoxon, and Mann-Whitney-U.

To sum up, \texttt{plotastic} stands as a unified and user-friendly solution
catering to the needs of researchers and data scientists, seamlessly
integrating statistical analysis with the power of plotting in Python.
It streamlines the workflow, translates \texttt{seaborn} parameters into
statistical terms, and supports extensive customization options for both
analysis and visualization.

\newpage




% ======================================================================
% == Sub-Discussion 
% ======================================================================
\unnsubsection{Discussion}%
\label{sec:C2_discussion}%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
As awareness of the complexities associated with multidimensional data in
biomedical research increases, there is a growing demand for tools that not only
simplify analysis but also enhance its intuitiveness and effectiveness
\cite{dunnExploringVisualizingMultidimensional2017}. \texttt{plotastic} is
designed to meet this demand by seamlessly integrating data visualization with
inferential statistics, making sophisticated statistical methods accessible to
researchers of all expertise levels. This integration could be pivotal as it
allows the visualization of data —how it is grouped and presented— to directly
guide the statistical analysis, reducing the need for in-depth statistical
knowledge and ensuring that the analyses are intuitively aligned with the visual
aspects of the data. This approach could not only simplify the analytical process
but also enhance the transparency and reproducibility of research findings.



\textbf{Statistical Features:}
A detailed list of implemented and planned features is provided on the GitHub
page of the project \cite{kuricMarkur4Plotastic2024}. \texttt{plotastic} is
comprehensive in its current scope, incorporating a robust suite of statistical
tests that cater to a wide range of research needs. It includes assumption tests
for normality, homoscedasticity, and sphericity, alongside classical statistical
tests such as ANOVA and t-tests, available in both parametric and non-parametric
forms, as well as paired and unpaired variants. However, its reliance on the
\texttt{pingouin} library means that \texttt{plotastic} is subject to the same
limitations as \texttt{pingouin} itself. For instance, it does not yet support
survival analysis tools like log-rank tests and Kaplan-Meier plots, which are
critical for certain biomedical applications. While there are external packages
that offer these capabilities, integrating them into \texttt{plotastic} could
significantly expand its utility and provide a more unified user experience
\cite{davidson-pilonLifelinesSurvivalAnalysis2019}.

One known issue in \texttt{plotastic} is its handling of multiple testing
corrections. Currently, \texttt{plotastic} might not correctly apply these
corrections when the data is split across different facets with their own y-axes
(facetted by \texttt{row} and \texttt{col} keywords), which can lead to
potentially incorrect statistical inferences. This is a fixable issue, and plans
are in place to address it in upcoming versions to ensure that corrections for
multiple testing are appropriately applied across the complete dataset.
Additionally, bivariate analysis tools like correlation and regression are not
yet implemented, since \texttt{plotastic} focused on data with a categorical
x-axis, which is more common in biomedical research.


\textbf{Plotting Features:} The plotting capabilities of \texttt{plotastic}
employ all of \texttt{seaborn}'s non-facetgrid plotting functions (e.g.
\texttt{sns.boxplot()}), which include a wide range of plot types but may not
cover all possible visualizations \cite{waskomSeabornStatisticalData2021}.
Future versions could expand the range of specialized plots, for example
QQ-plots. \texttt{plotastic} focuses on offering both high- and low-level
plotting configuration: \texttt{Multiplots} automate overlaying multiple plot
types, which is extremely useful for displaying raw data points alongside
aggregated statistics (barplots, boxplots, etc.), a feature that can be
cumbersome to implement manually. Low-level plotting configuration is supported
just like in \texttt{seaborn}, since plotastic uses \texttt{matplotlib} as its
backend. This level of flexibility is unique to \texttt{plotastic}, serving both
beginners and advanced users.

\textbf{Plot Annotation:} Annotating statistical results into plots (e.g. ***
above barplots) is a key requirement in modern biomedical journals and could be
key feature why researchers choose proprietary software like \textit{GraphPad
Prism} over other solutions. \texttt{plotastic} automates this process as well,
making it a strong competitor to other statistical software. This is especially
useful for re-arranging plots, since the statistical annotations are
automatically updated when the plot is re-drawn. This feature is unique to
\texttt{plotastic} and could be a key selling point for the software.


\textbf{Software Testing:} The development of \texttt{plotastic} adheres to
modern software engineering principles to ensure reliability and
maintainability. The project utilizes continuous integration practices, which
means that with every change to the codebase, a comprehensive test suite is
automatically run to identify potential bugs and ensure that new contributions
do not disrupt existing functionalities. This test suite covers approximately
\SI{79}{\percent} of the testable lines of code, a statistic tracked
automatically by an independent service called \texttt{codecov}, highlighting a
strong commitment to software quality \cite{Codecov2024}.



\textbf{Documentation:}
Documentation serves as a critical resource for enhancing user experience and
adoption, especially for software aimed at users with varying levels of
expertise. Currently, \texttt{plotastic}'s documentation is focused on basic
functionalities. These include detailed installation instructions, example
analyses using five test datasets from \texttt{seaborn} that are commonly used
in teaching statistics, guidelines on dimension switching with commands like
\texttt{DataAnalysis.switch()}, and tutorials on constructing and configuring
plots, annotating statistical data, and utilizing multiplot capabilities.

However, the documentation of \texttt{plotastic} could be significantly
enhanced. Currently, it lacks a dedicated website, relying instead on
GitHub-hosted Jupyter notebooks. While useful, these notebooks are not the most
user-friendly or maintainable format for documentation as they can be
challenging to navigate and don't update synchronously with software changes. A
more robust approach would involve leveraging services like \texttt{Read the Docs}
or \texttt{Sphinx} to generate and host documentation directly from the codebase
\cite{ReadDocs2024, Sphinx2024}. This would not only ensure
that the documentation remains up-to-date with the latest software developments
but also provide a more accessible and navigable user experience, meeting the
expectations of users who prefer a dedicated website for software documentation.



\textbf{Usability for Non-Statisticians:} \texttt{plotastic} aims to make
statistical analysis more accessible to researchers without extensive
statistical training by intuitively mapping plotting concepts to statistical
operations. To the author's knowledge, this approach is unique to
\texttt{plotastic} and has great potential to make statistics easier and
educational for non-statisticians. Still, the software requires responsible and
self-critical usage, as emphasized by the thorough disclaimer on its GitHub page
regarding the software's statistical robustness,
\cite{kuricMarkur4Plotastic2024}. The disclaimer highlights that while
\texttt{plotastic} can facilitate gaining practical experience with statistics
and provide a preliminary analysis, it is not a substitute for professional
statistical consultation. It is designed to aid users in generating
publication-grade figures and performing statistical tests, provided they have a
basic understanding of the procedures involved or have their results verified by
a statistician. To enhance usability for non-statisticians, \texttt{plotastic}
could incorporate a system to suggest appropriate statistical tests based on
data characteristics, like parametric tests for normally distributed data. This
feature would guide users in selecting the correct tests, thereby augmenting the
tool's functionality and broadening its appeal. Additionally, the GitHub page
provides critical guidelines for responsible statistical practice, urging users
to document their work in detail, understand the limitations of the tests
applied, and consult professionals to validate their findings, ensuring that
\texttt{plotastic} supports but does not replace thorough statistical analysis
\cite{sandveTenSimpleRules2013, kuricMarkur4Plotastic2024}.



\textbf{Usability for Non-Programmers:}
Despite the advantages of \texttt{plotastic}, its adoption among non-programmers
in biomedicine may be challenging due to its reliance on a command-line
interface (CLI), which is less intuitive for those accustomed to graphical user
interfaces (GUIs). However, the integration of advanced artificial intelligence
technologies, such as ChatGPT, presents a compelling case for embracing CLI.
Indeed, ChatGPT is believed to potentially revolutionize medical research
\cite{ruksakulpiwatUsingChatGPTMedical2023}.

Unlike GUIs, CLIs are highly compatible with text-based AI technologies, which
can significantly lower the barrier to entry. In fact, both ChatGPT-3.5 and -4
demonstrate impressive performance in python
\cite{arefinUnmaskingGiantComprehensive2023}. This is a game changer, since
researchers can now use similair tools as programmers and are only limited by
their methodological expertise to formulate a correct prompt
\cite{qureshiAreChatGPTLarge2023}\footnotequote{You can now recognize and learn
the language of almost anything with structure, and you can translate it to
anything with structure — so text-protein, protein-text. [...] Everybody is a
programmer, and the programming language of the future is called
`human.'}{kelleherNVIDIACEOThis2024}. For instance, when a software is not
working as intended, users of a GUI are likely to be stuck without help or
further research. Users of a CLI however, could utilize ChatGPT to ask for
code-corrections or explanations of the code line-by-line, but also for advice
on how to proceed with a statistical analysis and how to implement new features
(e.g. editing a plot). Attempts to integrate AI into GUIs however have proven
challenging \cite{gaoASSISTGUITaskOrientedDesktop2024}. 

Still, ChatGPT requires responsible use, as it is not sufficient as a standalone
tool for statistical analysis \cite{ordakChatGPTSkillsStatistical2023}. It
should also be noted that \texttt{plotastic} is not yet known to ChatGPT, but
could be included in future versions, depending on the popularity of
\texttt{plotastic}.

Overall, the transition to a new data analysis software, especially one
that incorporates coding, presents a learning curve. However, the advantages of
plotastic in terms of analytical clarity, speed, and depth are anticipated to
outweigh these initial challenges.


\textbf{Adoption and Open-Source Contributions:}
The adoption rate of \texttt{plotastic} is a critical factor for its
sustainability, particularly in the open-source environment where community
contributions can significantly support the author in improving and maintaining
the software. Since its publication in the Journal of Open Source Software on
March 9, 2024, \texttt{plotastic} has garnered attention with 41 visits and 8
\emph{stars} (similar to a `like' on social media platforms) on its GitHub page.
This level of engagement, while modest, shows initial interest and potential for
growth. Active involvement from the community is essential for ongoing
improvements; hence, efforts are being made to enhance the software's
documentation and structure to attract more contributors: \texttt{plotastic's}
GitHub page shows a detailed outline of the software's architecture as a class
diagram in unified modeling language (UML) format, helping potential
contributors orient themselves within \texttt{plotastic}'s several modules and
classes (shown in \apdxref{subapdx:classdiagr}). But further efforts are
required, e.g. only few functions are documented with docstrings, which help
understanding the purpose and usage of each function. Still, \texttt{plotastic}
is a general-purpose data analysis software designed not only for biologists but
for a broad range of scientific disciplines, making it a versatile tool with
promising potential for wider adoption.





\textbf{Contributions to Methodological Transparency and Biomedicine:}
\texttt{plotastic} standardizes statistical analysis by ensuring that it is
performed alongside visual representations. This integrated approach simplifies
both analysis and interpretation, facilitating smooth replication of analyses.
Although it streamlines the data analysis process, it is not a complete solution
to the reproducibility crisis in scientific research. Researchers must still
possess a basic understanding of data analysis principles and be cautious about
their reliance on scripting solutions like Python, which is less familiar to
some biomedical researchers. 

Statistical literacy and lack of training is a well-documented challenge among
clinicians and biomedical researchers, decreasing the confidence in
presenting their analyses in detail
\cite{lakhlifiIllusionKnowledgeStatistics2023, federerDataLiteracyTraining2016}.
Since \texttt{plotastic} alleviates some need for statistical knowledge by
automating the configuration of statistical tests, the room for error is
reduced, and the user can lay off some responsibility to the software, gaining
confidence in presenting their analysis transparently. 

Furthermore, \texttt{plotastic}'s compatibility with the Jupyter ecosystem
leverages \textit{``simple, intuitive ways to both capture and embed computational work
directly into our papers''} as advocated by
\citet{mesirovAccessibleReproducibleResearch2010}. This integration makes
\texttt{plotastic} not just a tool for analysis but also a means of enhancing
the accessibility and reproducibility of scientific work. As
\citet{pengReproducibleResearchComputational2011} suggests, the exploration of
data and analysis code may often be sufficient to verify the quality of
scientific claims. This seems plausible, given that statistical tests themselves
pose rigorous requirements on the data, and the results are often not
interpretable without the context data. Combining \texttt{plotastic} with
Jupyter Notebooks provides a compelling solution to transparently integrate and
document both intermediate results and analytical processes, thus furthering
scientific rigor and replicability.

Overall, \texttt{plotastic} is useful statistical tool with the potantial to
improve methodological transparency and reproducibility of research in
biomedicine.


% underscoring the potential of \texttt{plotastic} to improve
% the transparency of biomedical research.

% Provided that measurements are correctly
% performed and results are correctly interpreted, \texttt{plotastic} offers
% acceptable statistical analyses for a wide array of study types without
% requiring an in-depth understanding the underlying statistical principles.

% This feature is especially beneficial for
% biologists who might lack the statistical training to perform these analyses
% manually, but can gain confidence in presenting their analysis transparently
% using open source tools like \texttt{plotastic}. By allowing for the use of
% straightforward, unpaired non-parametric tests,

% \texttt{plotastic} provides a
% statistically sound framework for a variety of study types without requiring
% users to fully grasp the underlying statistical principles.



% \texttt{plotastic}'s approach to coupling statistical outputs with visual data
% representations aligns well with the needs for methodological transparency in
% scientific research. By ensuring that statistical analyses are both visible and
% directly related to the plotted data, \texttt{plotastic} facilitates a better
% understanding and replication of research findings, addressing key aspects of
% the reproducibility crisis.

% In summary, \texttt{plotastic} exemplifies a successful application of
% semi-automation in data analysis by making complex statistical analyses
% accessible and intuitive. It stands as a testament to the potential of
% well-designed software tools to impact scientific research significantly,
% enhancing both the reliability and efficiency of data analysis processes.



% Does plotastic make biomedicine more transparent?


% - It is a step in the right direction. The software is designed to
% streamline the data analysis process, ensuring that statistical tests are
% performed in conjunction with visual representations. This approach enhances
% methodological transparency, as the results of statistical analyses are
% immediately visible in the graphical outputs, facilitating the interpretation
% of results and the replication of analyses. However, the software is not a
% panacea for the reproducibility crisis in scientific research. While it
% simplifies the data analysis process, it does not eliminate the need for
% researchers to possess a basic understanding of data analysis principles. It is
% also heavily limited by biomedical researchers aversion towards scripting solutions like python.

% Statistical or Data illiteracy is a critical issue that's well researched for both clinicians and
% biomedical researchers \cite{lakhlifiIllusionKnowledgeStatistics2023,federerDataLiteracyTraining2016}.
% plotastic removes a lot of need for statistical knowledge, yet still performs complex statistical analyses,
% if the measurements were correctly performed and the results are correctly interpreted.
% Using unpaired non-parametric tests, plotastic provides statistically sound for a wide array of study types without
% the need for the user to understand the underlying statistical principles. This is a significant advantage for
% biologists, who often lack the necessary statistical training to perform these analyses manually, but could increase 
% the confidence to present their analysis transparently. 

% - However, \citet{pengReproducibleResearchComputational2011} claims that exploration of the
% data and the analysis code may be sufficient to verify the quality of the
% scientific claims. This seems plausible, given that statistical tests themselves pose rigorous
% requirements on the data, and the results are often not interpretable without
% the context data. In this sense, plotastic could be a valuable tool to
% enhance the transparency of research in biomedicine.
% - Plotastic integrates perfectly with the Jupyter ecosystem. \citet{mesirovAccessibleReproducibleResearch2010} called out for "simple,
% intuitive ways to both capture and embed our computational work directly into
% our papers". In this thesis, combining Jupyter Notebooks with plotastic could
% represent an intriguing solution to solve that problem.
% The full jupyter notebook of an example analysis is shown in \apdxref{subapdx:example_analysis}.
% that way, plotastic ensures that analyses are not only conducted with
% proper scientific rigor but also documented in a manner that facilitates
% replication




% The evaluation of plotastic within this thesis reflects its potential to address
% key challenges in the field of data analysis. The software integrates a
% comprehensive suite of statistical tests, such as ANOVA and t-tests, designed
% for adaptability and ease of use, leveraging the functionalities of pingouin.

% In the context of the reproducibility crisis in scientific research, plotastic
% offers noteworthy contributions, though it is not positioned as a universal
% remedy. The tool's unique approach to integrating statistical analysis with
% visual representation establishes a new paradigm, promoting methodological
% transparency. By mandating that statistical analyses accompany relevant
% graphical outputs, plotastic ensures that analyses are not only conducted with
% proper scientific rigor but also documented in a manner that facilitates
% replication, provided the user possesses proficiency in Python.

% Does plotastic make biomedicine more transparent?
% - It is a step in the right direction. The software is designed to
% streamline the data analysis process, ensuring that statistical tests are
% performed in conjunction with visual representations. This approach enhances
% methodological transparency, as the results of statistical analyses are
% immediately visible in the graphical outputs, facilitating the interpretation
% of results and the replication of analyses. However, the software is not a
% panacea for the reproducibility crisis in scientific research. While it
% simplifies the data analysis process, it does not eliminate the need for
% researchers to possess a basic understanding of statistical principles and
% Python programming.





% Usability is a critical attribute of analytical software, particularly as
% researchers confront increasingly complex datasets. While the developer's
% intimate familiarity with plotastic may bias perceptions of its ease of use, it
% is recognized that novices may initially encounter challenges. Nevertheless,
% plotastic is distinguished by its user-friendly interface, enabling users with
% minimal statistical training to perform sophisticated analyses by intuitively
% mapping plotting concepts to statistical operations.

% The transition to a new analytical framework, especially one that incorporates
% coding, presents a learning curve. However, the advantages of plotastic in terms
% of analytical clarity, speed, and depth are anticipated to outweigh these
% initial challenges. Support mechanisms, such as assistance from advanced AI like
% ChatGPT, are available to mitigate these hurdles, supporting users across
% varying levels of expertise.

% In conclusion, plotastic is posited as a valuable tool in the landscape of
% scientific research, offering a means to enhance the reproducibility and
% efficiency of data analysis. Its development ethos emphasizes simplifying
% complex analytical tasks, thereby contributing to the broader goal of fostering
% transparent and reproducible research practices.


% DO we apply the principles of Semi-Automation to the software?

