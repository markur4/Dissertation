

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% ======================================================================
% == Discussion: Coding
% ======================================================================

% ======================================================================
\unnsubsection{Semi-Automation was Critical for Establishing \textit{in vitro} Methods}%
\label{sec:discussion_semi_automated_analysis}%
\textit{In vitro} research is valued for their speed at creating precise data
\cite{moleiroCriticalAnalysisAvailable2017}. In this work, the development and
publication of innovative \textit{in vitro} methodologies necessitated the
adoption of semi-automated data analysis tools. These novel methods introduced
complexities that span multiple experimental parameters, making the results
multidimensional. This demanded precise, efficient and standardized data
handling capabilities which were facilitated by Python tools like
\texttt{seaborn} and \texttt{plotastic} \cite{waskomSeabornStatisticalData2021,
    kuricPlotasticBridgingPlotting2024}.


\textbf{Inherent Multidimensionality of Adhesion Studies:}
Cell adhesion studies often involve multiple independent parameters, posing
significant analytical challenges. Two critical dimensions are particularly
notable: \emph{`Subpopulation'} and \emph{`Time'}. Analyzing cell adhesion often
involves isolation of adherent and non-adherent subpopulations, effectively
introducing \textit{`Subpopulation'} as a vital dimension in the dataset
\cite{dziadowiczBoneMarrowStromaInduced2022}. This study specifically
categorized cells into three levels of MSC-interaction: \CMina, \nMAina, and
\MAina, representing \INA cells incubating in MSC-conditioned medium, \INA cells
not adhering to MSCs, and \INA cells adhering to MSCs, respectively.
Furthermore, the dynamic nature of cell adhesion processes is profoundly
influenced by the factor \emph{`Time'}, making it a crucial experimental
parameter for investigation \cite{reblTimedependentMetabolicActivity2010,
    mckayCellcellAdhesionMolecules1997,
    bolado-carrancioPeriodicPropagatingWaves2020a}. In fact, the lack of time-series
measurements was brought forward as a central roadblock%
\footquote{The lack of time-series measurements in single-cell
    multi-omics (e.g., gene expression dynamics, protein oscillations, histone
    marks spreading, etc.) and cell population fluctuations (i.e., ecological
    dynamics), in patient-derived tumor and liquid biopsies, remains a central
    roadblock in reconstructing cancer networks as complex dynamical
    systems.%
}{uthamacumaranReviewMathematicalComputational2022}%
for understanding cancer as a dynamic system.
\cite{uthamacumaranReviewMathematicalComputational2022}. This work includes
extensive time-lapse microscopy experiments utilizing a high time resolution
(\SI{1}{frame} every \SI{15}{\minute}), similar to those time resolutions used
by \citet{purschkePhototoxicityHoechst333422010}. This precision was required
for key mechanistic insights on hMSC-\INA interaction dynamics. These included
identifying rolling movements of \nMAina daughter cells around \MAina mother
cells, measuring the minimum time for \INA detachments to begin, and measuring
the time required for daughter cells to re-attach to the hMSC monolayer, etc.
Next to mechanistic insights, adhesion time played a crucial methodological role
in this study as well: During the V-Well adhesion experiments, we did not know
initially how long \INA cells required to form strong adhesion with hMSCs before
pelleting \nMAina, but required a timepoint with hour precision to capture
detachments after cell division that was accelerated through prior cell cycle
synchronization at M-Phase.

The extensive facetting features of \texttt{seaborn} and \texttt{plotastic} were
essential for visualizing these multidimensional datasets, allowing for quick
exploration of the data \cite{waskomSeabornStatisticalData2021}.


\textbf{Further Contributions and Remedies to Multidimensional Complexity:}
In addition to \textit{`Subpopulation'} and \textit{`Time'}, this study faced
additional layers of complexity that were managed through semi-automated
analysis.

Experiments typically involved at least three biological replicates and
corresponding technical replicates. Although replicates were not treated as
independent variables \dashed{instead serving for displaying variance}
they can add substantially to the data management workload. In this work,
semi-automation nullified the manual burdens of handling technical replicates:
\texttt{pandas} was used to automate aggregation of technical replicates into
means after removing technical outliers thorugh z-score thresholding, while the
jupyter notebook format allowed for reviewing filtered data for specific data
losses. The removal of technical noise was especially relevant for qPCR data,
where low gene expression can lead to sudden increase in Ct value (non-detects).
In fact, the decision to remove or impute non-detects is under active
discussion, however, available algorithms are hard to understand for non
bioinformaticians, but also do not separate biological from technical variance,
which is considered bad practice by
\citet{motulskyIntuitiveBiostatisticsNonmathematical2018}
\cite{mccallNondetectsQPCRData2014, sherinaMultipleImputationDirect2020}.
Semi-automation also nullified the burden of handling biological replicates: The
automatic aggregation of datapoints during plotting is a key feature of
\texttt{seaborn}, on which \texttt{plotastic} was built. Without such
automation, calculating means and standard deviations for simple barplots would
have required extensive manual computation in \textit{Microsoft Excel}, or
tedious plot configurations in \textit{GraphPad Prism} due to limited facetting
functionality of multiple variable tables \cite{GraphPadPrism102024}.

Replicates can expand datasets as this factor comprises a lot of levels.
Similarly, the factor \textit{`Gene'} multiplied the dataset by a total of 30
genes when validating RNAseq data with RT-qPCR. With three subpopulations, one
timepoint, eleven biological replicates, and three technical replicates, the
qPCR dataset used in this study grew to 2970 datapoints to be statistically
analyzed and visualized. This is a manageable size for manual analysis, but the
effort involved illustrates the definition of semi-big data.

Methodological variability also introduced additional dimensions: The Well Plate
Sandwich Centrifugation (WPSC) used two different techniques to dissociate
\MAina cells from the hMSC monolayer: Strong pipetting
(\emph{`Wash'}) and repeated Accutase treatment followed by magnetic activated
cell sorting (\emph{`MACS'}). These variations, recorded as the factor
\textit{`method'}, further complicated the dataset. Although this distinction is
not discussed in this work \dashed{rather pooled into one group}, this
showcases how protocol changes can add dimensions to the dataset that are
not necessarily relevant for the biological question but essential for
method optimizations and validation.



\textbf{Agility During Establishment of V-Well Assay:}
The concept of agility in laboratory research, inspired by the Agile Manifesto's
principle of \emph{``Responding to change over following a plan''}
\cite{ManifestoAgileSoftware2001}, is increasingly relevant in biomedical
research \cite{westReinventingResearchAgile2018,
    quanbeckApplyingConceptsRapid2022}. This adaptive approach was particularly
crucial during the development of the V-Well adhesion assay in this study. This
experiment was planned such that the author performed fluorescent readout using
microscopy and preliminry analysis, while a technical assistant prepared the
samples for the next timepoint. Semi-automation accelerated the preliminary data
analysis and visualization to a point that results were reviewable before the
next sample timepoint was prepared and ready for fluorescent readout. This
enabled immediate adjustments to the experimental protocol inbetween sample
measurements, allowing for quick troubleshooting of small and avoidable problems
that are often unforeseeable when establishing new methodologies. Without such
agility, these problems would have been identified after the experiment,
requiring a complete re-run of a very work-intensive experiment that included cell
cycle synchronization. Such an agile and adaptive work environment, facilitated
by python tools and \texttt{seaborn}, proved invaluable for refining the
\textit{in vitro} methods being developed.

Additionally, the simplicity
offered by \texttt{seaborn} for complex data plotting, such as the cell cycle
profiling shown in \apdxref{subapdx:figs}{fig:S3}, which required minimal code
to produce a detailed series of 24 histograms, underscores the utility of
semi-automation in enhancing laboratory efficiency. While this work does not
quantify the full benefits of semi-automation, the author's experiences suggest
potential impacts on the speed and adaptability of method development in
biomedical research.






% ======================================================================
\unnsubsection{\texttt{plotastic} Exceled in Re-Doing Statistical Analyses and Plots}%
\label{sec:discussion_plotastic}%
Establishing new methods of \textit{in vitro} dissemination required not just
innovative experimental protocols, but also adaptive ways to visually present
complex data. This need for adaptability is crucial during the publication
process, where researchers must often experiment with different ways to visually
represent their findings to best convey their significance. This process
typically involves frequent adjustments to how data is displayed in plots. Such
adjustments become especially cumbersome when subsequent adjustments are
involved. Traditional tools (\textit{Microsoft Excel} or \textit{Graphpad
    Prism}) fail at handling semi-big data, while Python packages like
\textit{seaborn} reach their limits in terms of adaptability, making the
development of \texttt{plotastic} a critical step in this work.

\texttt{plotastic} addresses these challenges by not only automating statistics,
but also by enhancing the adaptability of data visualization as well, making it
easier to modify how data is presented without repetitive manual adjustments.
The author saw four key steps that required streamlining through \texttt{plotastic}:
\begin{enumerate}
    \item {Re-arranging facets}
    \item {Plotting multiple layers of different plot types}
    \item {Statistical Re-Analysis and Re-Annotation}
    \item {Fine-Tuning for publication grade quality}
\end{enumerate}

These adjustment steps made re-plotting tedious, since a change in prior steps
required a complete re-work of following steps, something which
\texttt{plotastic} prevented. Its key design feature is the centralized
storage of facetting parameters (\facetparams). These parameters define which
data points are shown on the x-axis, what categories are highlighted by color
(\texttt{hue}), and how data is grouped into separate plots (by columns and/or
rows) into separate plots. This centralization means that once these parameters
are set, they not only automate statistical analysis, but also can be
automatically applied across all subsequent adjustments made to the plot. This
contrasts with \texttt{seaborn}, where changing these parameters
required adjusting multiple lines of subsequent code.

\textbf{Re-arranging Facets:} \texttt{plotastic}'s \texttt{.switch()} method
allowed for easily shifting the arrangement of plots \dashed{for
    example, switching the data represented on the x-axis with that represented by
    color} to explore different perspectives of the data quickly. This proved
particularly useful when trying to find the most effective way to illustrate
complex interactions or trends that might not be immediately apparent. In
\texttt{seaborn}, changing facets is easy and proved useful during
intermediate data analysis, but unfeasable when plots involved multiple
layers, sophisticated style edits or statistical annotations, as this can
require re-writing subsequent adjustments.


\textbf{Plotting Multiple Layers of Different Plot Types:}
Modern journal standards increasingly demand the representation of individual
datapoints alongside aggregated data, for example plotting datapoints above a
bar- or boxplots. \texttt{seaborn} does not automate this, but can require
calling two plotting functions in sequence, e.g. \texttt{sns.boxplot()} followed
by \texttt{sns.swarmplot()}. This can get repetitive, as adjusting the
style of these plots to match each other, e.g. defining the point
size or transparency of individual data points to fit into a barplot.
\texttt{plotastic} was designed for multi-layered plotting, offering single-line
functions for plot combinations with pre-configured style-parameters.

\textbf{Statistical Re-Analysis and Re-Annotation}
To the author's knowledge, \texttt{plotastic}'s capability of streamlining
statistical re-analysis is unique and unmatched. \texttt{seaborn} alone can not
perform this without multiple lines of \texttt{statannotations}
\cite{charlierTrevismdStatannotationsV02022}. \texttt{plotastic} automates the
inclusion of statistical annotations directly into plots. This is a significant
enhancement because it ensures that any statistical significance noted in the
data is immediately visible and correctly updated whenever the data presentation
is changed. This feature proved particularly useful during the peer review
process of \citet{kuricModelingMyelomaDissemination2024}, where a reviewer asked
for a complete statistical analysis of Chapter\,1\,\ref{fig:5}\,D, which at that
time included only paired t-tests between selected groups.

\textbf{Fine-Tuning for Publication Grade Quality:}
\texttt{plotastic} simplified the creation of publication-quality figures by
automating style adjustments that are typically manually coded with
\texttt{matplotlib} when using \texttt{seaborn}. These include adjustments like
angled x-axis labels or consistent visual styles across multiple figures, which
are important for maintaining the professional appearance of published data.


\textbf{Key Insight: Could \texttt{plotastic} Address a Re-Analysis Bottleneck?}
Re-doing analyses and plots is often overlooked bottlenecks in the
reproducibility of scientific research, although it does overlap with two
principles of the FAIR-guidelines for scientific data management and
stewardship: Interoperability\footquote{Interoperability\,â€”\,the ability of
    data or tools from non-cooperating resources to integrate or work together with
    minimal effort.}{wilkinsonFAIRGuidingPrinciples2016} and Re-Usability
\cite{wilkinsonFAIRGuidingPrinciples2016}. This challenge was exemplified during
this work's experiments using RT-qPCR. The field of qPCR, where reproducibility
issues have been notoriously prevalent. As
\citet{bustinReproducibilityBiomedicalResearch2014} noted, many publications
using PCR-based methods have been seriously flawed, underscoring the need for
updated approaches \cite{bustinNeedTransparencyGood2013,
    ruiz-villalbaUseMisuseCq2021}. Furthermore, the evolution of the
$\Delta\Delta$Ct formula over recent years highlights the dynamic nature of data
analysis standards in biomedicine \cite{pfafflNewMathematicalModel2001a,
    ramakersAssumptionfreeAnalysisQuantitative2003,
    ruijterEfficiencyCorrectionRequired2021}. Despite these challenges, current data
analysis infrastructures seldom facilitate a smooth revision or complete redoing
of figures, which could hamper efforts to re-analyse and apply the latest
techniques to existing datasets, which could be requested e.g. during
peer-review \cite{wilkinsonFAIRGuidingPrinciples2016}. In response,
\texttt{plotastic} was specifically designed to streamline the reconfiguration
and reanalysis of data visualizations. This work serves as a case study showing
that \dashed{according to the author's experiences} the manual effort
involved was effectively reduced, making the task of re-analysis seem a lot more
inviting, especially for handling semi-big data.




% ======================================================================
\unnsubsection{\textit{\textbf{Conclusion\,1}: Demonstrating the Advantages of Semi-Automation in
        Biomedical Data Analysis}}%
\label{sec:discussion_conclusion_semi_automation}%
This thesis illustrates the challenges and solutions associated with managing
the inherent complexity of adhesion studies and related methodologies, such as
Cell Cycle profiling. These methodologies necessitate sophisticated data
handling tools to address two primary challenges: (1) the multidimensionality of
semi-big data and (2) the rapid iterative loop of results evaluation and protocol
adjustments, a process for which \textit{in vitro} methods are valued.

\texttt{seaborn} and \texttt{plotastic} have been instrumental in addressing
these challenges. \texttt{seaborn} facilitated the rapid processing of
intermediate results during method development, while \texttt{plotastic} was
crucial for crafting publication-grade analyses and figures, filling in the
capabilities that \texttt{seaborn} lacks. This includes facilitating the easy
(re-)design of visualizations and statistical analyses, which are critical for
late-stage data processing.

Though this work does not provide empirical evidence quantifying the benefits of
semi-automation, it serves as a practical case study demonstrating the
transformative potential of such technologies in biomedical research. The
integration of semi-automation tools streamlined complex \textit{in vitro}
methodologies, significantly enhancing operational agility. This case study
bridges biomedical research with bioinformatics, highlighting how
semi-automation can reduce data analysis workloads and enable researchers to
focus more on exploratory research within the laboratory setting.

To the author's experience, the gained efficiencies not only saved valuable time
but also enhanced the clarity and communicative power of the research findings.
This is particularly crucial in fields like myeloma dissemination, where precise
and transparent data presentation is essential for advancing understanding and
treatment strategies. This conclusion suggests a need for further empirical
research to validate these benefits more broadly and encourage wider adoption of
semi-automation tools in biomedical research.

However, adopting \texttt{plotastic} poses its own set of challenges,
particularly in the realm of biomedicine where researchers may prefer graphical
user interfaces (GUIs) over command-line interfaces (CLIs). While
\texttt{plotastic} offers a powerful CLI that is efficient and capable of
handling complex data manipulation and visualization tasks, the transition from
GUIs to CLIs can be intimidating for those accustomed to more visual interaction
with software. This barrier can be mitigated by the integration of tools like
ChatGPT, which can facilitate the use of CLIs by offering context understanding,
code assistance, and error identification.



% % ======================================================================


