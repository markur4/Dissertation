
% Zusätzliche Einleitung und Diskussion: Herr Kuric soll bitte eine ergänzende Einleitung und Diskussion in dem Kapitel zu seiner JOSS-Publikation hinzufügen, die folgende Informationen enthalten:

% Darstellung von Umfeld, Aufgabenstellung und Signifikanz für die
% biomedizinische Anwendung
% (warum braucht es die Biomedizin?)

% Darstellung der Anforderungen an die Programmierung: Integration von
% Informationen, die die spezifischen Anforderungen verdeutlichen,
% welche die Programmierung der Software erforderlich gemacht haben.
% (warum habe ich es gebraucht?) 

% Darstellung der Nutzbarkeit für Naturwissenschaftler: Klare und auch
% für Nicht-Informatiker verständliche Darstellung, welche konkreten
% Anwendungsmöglichkeiten die Software für Naturwissenschaftler bietet.
% (warum ist es nützlich?)

% Mit einer angemessenen Einleitung und Diskussion würde zum einen den
% Guidelines der GSLS entsprochen, die für alle zugrunde gelegt werden.
% Zum anderen würde es auch dem großen Anteil von Nicht-Informatikern in
% der GSLS erlauben, den Hintergrund und die Signifikanz und
% Verwendungsmöglichkeiten des entwickelten Codes besser zu verstehen.
% Die GSLS hat sich mit der Aufnahme von informatischen Projekten
% interdisziplinär geöffnet. Gleichzeitig erwarten wir damit aber auch
% von den Doktorierenden den Willen, die Arbeit in einer
% interdisziplinären Form in der Thesis zu präsentieren.



% ======================================================================
% == Chapter 2
% ======================================================================

% \unnsubsection{Introduction: Making Statistics Accessible to Biologists and Accelerating Laboratory Workflows}
\unnsubsection{Introduction}
\
The reproducibility crisis in research highlights a significant challenge in
contemporary biosciences, where a substantial portion of studies faces
reproducibility issues~\cite{begleyReproducibilityScienceImproving2015}. One
critical yet often overlooked aspect contributing to this crisis is data
management. The literature most often refers to \textit{big data} as the main
challenge~\cite{gomez-cabreroDataIntegrationEra2014}. However, these challenges
are also present in smaller datasets, which the author refers to as
\textit{semi-big data}. This term describes datasets that, while not extensive
enough to necessitate advanced computational tools typically reserved for
\textit{big data}, are sufficiently large to render manual analysis very
time-intensive.~\textit{Semi-big data} is often generated by methods like
automated microscopy or multiplex qPCR, which produce volumes of data that are
manageable on a surface level, but pose substantial barriers for in-depth,
manual reproducibility~\cite{bustinReproducibilityBiomedicalResearch2014}. This
is further complicated by the complexity inherent in multidimensional datasets.
For example, the qPCR experiment from Chapter 1, Fig. 4 involves the analysis of
19 genes across in three subpopulations, including eleven biological and three
technical replicates, resulting in a total of 1881 data points that are all
assigned to a complex set of experimental variables. Without a clearly
documented data analysis protocol and standardized data formats, the
reproduction of such analysis becomes extremely challenging, if not
impossible~\cite{bustinReproducibilityBiomedicalResearch2014}.


The evolving standards in data analysis advocate for the standardization of
analytical pipelines, rationalization of sample sizes, and enhanced
infrastructure for data storage, addressing some of these
challenges~\cite{goodmanWhatDoesResearch2016,wilkinsonFAIRGuidingPrinciples2016}.
However, these advancements can place undue pressure on researchers,
particularly those with limited training in statistics, underscoring the need
for intuitive, user-friendly analytical
tools~\cite{gosselinInsufficientTransparencyStatistical2021,armstrongWhenUseBonferroni2014,gomez-lopezPrecisionMedicineNeeds2019}

In this context, \texttt{plotastic} emerges as a tool designed to democratize access to
sophisticated statistical analysis, offering a user-centric interface that
caters to researchers across varying levels of statistical proficiency. By
integrating robust statistical methodologies within an accessible framework,
\texttt{plotastic} aims to contribute to enhancing the reproducibility and
integrity of research in the biosciences~\cite{gomez-cabreroDataIntegrationEra2014}.



initially, the need to develop \texttt{plotastic} arose during this project. The
first is to address the author's need for a tool that could handle the complex,
multidimensional data generated by e.g. qPCR experiments. These experiments
typically involve the analysis of multiple genes across several time points and
biological replicates, resulting in datasets that are challenging to analyze
manually. The author's experience with traditional statistical software, such
as Prism, revealed that these tools required extensive manual input, making
them unsuitable for the efficient analysis of complex, multidimensional data. -
The second was to increase speed. THis is required for developing methods


Since \texttt{plotastic} optimizes the analysis of \textit{semi-big data}, we
introduce the term \textit{semi-automation} to distinguish itself from the fully
automated pipelines used for \textit{big data}. Semi-automation is
defined as the following aspects:
\begin{enumerate}
    \item \textbf{Semi-big input:} The input size is oriented towards
          \textit{semi-big data}, which is characterized as being manageable by
          manual analysis, yet highly time inefficient, and probably impossible
          to re-analyse by someone else than the researcher.
    \item \textbf{Standardized input} The input follows a standardized format (e.g. long-format)
    \item \textbf{Minimize user configuration:} User configuration is strictly
          minimized. The user is never asked to pass the same parameters twice. This
          reduces the risk of human error and time spent on configuration.
    \item \textbf{Default configuration provides acceptable results:} If the
          user does not provide any manual configuration, the pipeline should
          provide acceptable results. Options should be provided to allow a
          level of flexibility to adapt the pipeline to the user's needs.
    \item \textbf{Small Reviewable Processing Steps:} The analysis steps are
          structured into small processes that can be combined to form a
          complete analysis pipeline. That way, each step can act as a stage for
          quality control to improve error detection and troubleshooting. For a
          statistical analysis, that means the processing steps are separated
          into 3 steps, those being assumption testing, factor analysis and
          post-hoc testing.
    \item \textbf{Isolated Steps:} Processing steps should work independently
          from another, in the best case only depending on the raw data input.
          If a processing step depends on the output from other steps, the
          software should tell the user what exact steps it expects.
    \item \textbf{Human readable outputs:} Every processing step may provide
          an output that is not necessarily standardized, but is required to be
          human readable to ensure reviewability.

\end{enumerate}

% NOT found, don't care
% Marino, S., et al. (2018). Big Data and Models of Culture: Ongoing Challenges and Possible Solutions. Big Data & Society, 5(2).

% NOT FOUND, required
% Lynch, C., et al. (2019). Big data: How do we measure up? Current Opinion in Systems Biology, 15, 77-84.

% Wrong citation
% Ioannidis, J. P., Fanelli, D., Dunne, D. D., & Goodman, S. N. (2014). Meta-research: Evaluation and Improvement of Research Methods and Practices. PLoS Biol, 12(10), e1002016.
% Peng, R. D. (2011). Reproducible research in computational science. Science, 334(6060), 1226-1227.





\newpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Challenges:
- Reproducibility crisis?
- Data is exploding
- Demands for rigorous statistical analysis are increasing
- Biologists are not trained in statistics


The demands are rising: \cite{moreno-indiasStatisticalMachineLearning2021}
% Nevertheless, although many statistics and machine learning approaches and tools
% have been developed, new techniques are needed to deal with emerging
% applications and the vast heterogeneity of microbiome data. We review and
% discuss emerging applications of statistical and machine learning techniques in
% human microbiome studies and introduce the COST Action CA18131 “ML4Microbiome”
% that brings together microbiome researchers and machine learning experts to
% address current challenges such as standardization of analysis pipelines for
% reproducibility of data analysis results, benchmarking, improvement, or
% development of existing and new tools and ontologies.
% sample size, open source will be critical



As laid out in the introduction, one can doubt if a PhD student without coding
skillsis at its max efficiency.

Why does Biomedicine need plotastic?:
- Thorough analysis has become a standard, with assumption testing, omnibus
tests and post-hoc analyses for every experiment.
- But data is increasing
- Example of my data?
- The number of dedicated statisticians is limited
- The know-how of statistics in biology is limited, for example, Some authors
ignored the problem of multiple testing while others used the method
uncritically with no rationale or discussion \cite{pernegerWhatWrongBonferroni1998,armstrongWhenUseBonferroni2014}


Why did I need plotastic?

Why do biologists need plotastic?
- Assays output more data in shorter time, e.g. multiplex qPCR
- example: 20 genes, 3 timepoints, 11 biological replicates, (all 3
technical replicates already averaged)
- 20 * 3 * 11 = 660 data points

this is multidimensional data:  660 data points spread across two dimensions: time
and gene

-in manual analysis e.g. in Excel, the user has to manually select the
data, copy it, paste it into a new sheet, and then perform the
statistical test. In Prism, the user has to select the data, click on
the statistical test, and then select the data again. This is not only
time-consuming, but also prone to

- Re-Analysis: The user has to repeat the process for every gene and
timepoint. This is not only time-consuming, but also prone to errors.

shortly Describe Main Packages in more detail:
- seaborn: It multidimensional data
- pingouin: It's a statistical package

% ======================================================================
% == Paper 2 ===========================================================
% ======================================================================
% ## Import paper here
\addpdf[.93]
{Software Article: Journal of Open Source Software}
{PUBLICATIONS/§-kuricPlotasticBridgingPlotting2024.pdf}



% ======================================================================
% == Sub-Discussion 
% ======================================================================
\unnsubsection{Discussion}
\
Is plotastic USABLE for biologists?
- Yes but use is limited by minimal knowledge of Python
- However, that is subject to change as Python is becoming more popular
in biology and AI assisted coding decreased the barrier to entry
significantly. Tools like github copilot are able to generate code, fix
bugs and suggest improvements. This is a game changer for biologists
that are not familiar with programming.
- Furthermore, installing and using plotastic for biologists is overestimated. These
steps re needed:
- Install anaconda from the internet
- Open the terminal
- Type \texttt{pip install plotastic}
- Check Rea


The evaluation of plotastic within this thesis reflects its potential to address
key challenges in the field of data analysis. The software integrates a
comprehensive suite of statistical tests, such as ANOVA and t-tests, designed
for adaptability and ease of use, leveraging the functionalities of pingouin.

In the context of the reproducibility crisis in scientific research, plotastic
offers noteworthy contributions, though it is not positioned as a universal
remedy. The tool's unique approach to integrating statistical analysis with
visual representation establishes a new paradigm, promoting methodological
transparency. By mandating that statistical analyses accompany relevant
graphical outputs, plotastic ensures that analyses are not only conducted with
proper scientific rigor but also documented in a manner that facilitates
replication, provided the user possesses proficiency in Python.

Usability is a critical attribute of analytical software, particularly as
researchers confront increasingly complex datasets. While the developer's
intimate familiarity with plotastic may bias perceptions of its ease of use, it
is recognized that novices may initially encounter challenges. Nevertheless,
plotastic is distinguished by its user-friendly interface, enabling users with
minimal statistical training to perform sophisticated analyses by intuitively
mapping plotting concepts to statistical operations.

The transition to a new analytical framework, especially one that incorporates
coding, presents a learning curve. However, the advantages of plotastic in terms
of analytical clarity, speed, and depth are anticipated to outweigh these
initial challenges. Support mechanisms, such as assistance from advanced AI like
ChatGPT, are available to mitigate these hurdles, supporting users across
varying levels of expertise.

In conclusion, plotastic is posited as a valuable tool in the landscape of
scientific research, offering a means to enhance the reproducibility and
efficiency of data analysis. Its development ethos emphasizes simplifying
complex analytical tasks, thereby contributing to the broader goal of fostering
transparent and reproducible research practices.